import os
import time
import json
import requests
import re
import traceback
from datetime import datetime
from dotenv import load_dotenv
load_dotenv()
import random
import json as pyjson

# ===[ì…€ë ˆë‹ˆì›€ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬]===
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from selenium.webdriver.chrome.options import Options

# ===[ì„¤ì • ì˜ì—­]==========================
USER_ID = os.environ.get("CNU_ID")
USER_PW = os.environ.get("CNU_PW")
DISCORD_WEBHOOK_URL = os.environ.get("with_WEBHOOK_URL")
MONITOR_WEBHOOK_URL = os.environ.get("MONITOR_WEBHOOK_URL")

LIST_URL = "https://with.cnu.ac.kr/ptfol/imng/icmpNsbjtPgm/findIcmpNsbjtPgmList.do"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_FILE = os.path.join(BASE_DIR, "..", "data", "with_data.json")
# ==========================================

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', text).strip()

def parse_str_to_dt(date_str):
    if not date_str: return None
    try:
        if ":" in date_str:
            return datetime.strptime(date_str, "%Y.%m.%d %H:%M")
        else:
            return datetime.strptime(date_str, "%Y.%m.%d")
    except:
        return None

def calculate_multi_info(sub_items):
    if not sub_items: return None
    app_ends, oper_starts, oper_ends, capacities = [], [], [], []
    for item in sub_items:
        if item['apply_raw']:
            parts = item['apply_raw'].split('~')
            if len(parts) > 1:
                dt = parse_str_to_dt(parts[1].strip())
                if dt: app_ends.append(dt)
        if item['oper_raw']:
            parts = item['oper_raw'].split('~')
            if len(parts) > 0:
                dt_s = parse_str_to_dt(parts[0].strip())
                if dt_s: oper_starts.append(dt_s)
            if len(parts) > 1:
                dt_e = parse_str_to_dt(parts[1].strip())
                if dt_e: oper_ends.append(dt_e)
            elif len(parts) == 1 and dt_s:
                oper_ends.append(dt_s)
        if item['capacity']:
            nums = re.findall(r'\d+', item['capacity'])
            if nums: capacities.append(int(nums[0]))
            
    result = {"apply": "", "oper": "", "capacity": ""}
    if app_ends:
        result['apply'] = f"~{min(app_ends).strftime('%m.%d')}"
    if oper_starts and oper_ends:
        min_s, max_e = min(oper_starts), max(oper_ends)
        if min_s.date() == max_e.date():
            result['oper'] = f"{min_s.strftime('%m.%d %H:%M')}~{max_e.strftime('%H:%M')}"
        else:
            result['oper'] = f"{min_s.strftime('%m.%d')}~{max_e.strftime('%m.%d')}"
    if capacities:
        result['capacity'] = f"{min(capacities)}ëª…"
    return result

def extract_details(container):
    data = {"apply_raw": "", "oper_raw": "", "capacity": ""}
    try:
        for dl in container.find_elements(By.CSS_SELECTOR, ".etc_info_txt dl"):
            dt = dl.find_element(By.TAG_NAME, "dt").get_attribute("textContent")
            dd = dl.find_element(By.TAG_NAME, "dd").get_attribute("textContent")
            if "ì‹ ì²­" in dt: data["apply_raw"] = clean_text(dd)
            elif "ìš´ì˜" in dt or "êµìœ¡ê¸°ê°„" in dt: data["oper_raw"] = clean_text(dd)
    except: pass
    try:
        for dl in container.find_elements(By.CSS_SELECTOR, ".rq_desc dl"):
            dt = dl.find_element(By.TAG_NAME, "dt").get_attribute("textContent")
            if "ëª¨ì§‘" in dt or "ì •ì›" in dt:
                data["capacity"] = clean_text(dl.find_element(By.TAG_NAME, "dd").get_attribute("textContent"))
    except: pass
    return data

def post_to_discord_safe(content):
    if not DISCORD_WEBHOOK_URL or "http" not in DISCORD_WEBHOOK_URL: return
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=1)
    session.mount('http://', HTTPAdapter(max_retries=retry))
    session.mount('https://', HTTPAdapter(max_retries=retry))
    try:
        # ë©˜ì…˜ ì—†ì´ ë‚´ìš©ë§Œ ì „ì†¡
        session.post(DISCORD_WEBHOOK_URL, json={"content": content}, timeout=10)
        print("âœ‰ [ì „ì†¡ ì„±ê³µ]")
    except Exception as e:
        send_simple_error_log("ê²Œì‹œë¬¼ ì „ì†¡ ì‹¤íŒ¨")
        print(f"âš  [ì „ì†¡ ì‹¤íŒ¨] {e}")

# ===[ë©”ì‹œì§€ ë””ìì¸ ìˆ˜ì • ì˜ì—­]===
def create_message_content(info):
    """
    ** â–¶ D-20 | ì œëª© **
    > [Sub Title] ì™¸ Nê°œ ë°˜ (ë©€í‹°ì¼ ê²½ìš°)
    > ì‹ ì²­: ë‚ ì§œ | ìš´ì˜: ë‚ ì§œ | ì •ì›: Nëª…
    """
    # 1. ì•„ì´ì½˜ ë° D-Day ì„¤ì •
    icon = "â–¶" if info['is_multi'] else "â–·"
    d_day_part = f"{info['d_day']} | " if info['d_day'] else ""
    
    # 2. ì œëª©
    header = f"** {icon} {d_day_part}[{info['title']}](<{info['link']}>) **\n"
    
    body_lines = []

    # 3. (ë©€í‹° í”„ë¡œê·¸ë¨ì¸ ê²½ìš°) ì„¸ë¶€ í”„ë¡œê·¸ë¨ ëŒ€í‘œ í‘œì‹œ
    if info['is_multi'] and info['sub_items']:
        first_sub = info['sub_items'][0]['title']
        count = len(info['sub_items']) - 1
        sub_text = f"[{first_sub}] ì™¸ {count}ê°œ ë°˜" if count > 0 else f"[{first_sub}]"
        body_lines.append(sub_text)

    # 4. ì‹ ì²­/ìš´ì˜/ì •ì› ì •ë³´ ì¡°ë¦½
    parts = []
    
    # ë‚ ì§œ í¬ë§·íŒ… ë‚´ë¶€ í•¨ìˆ˜
    def simple_date(raw):
        m = re.search(r'\d{4}\.(\d{2}\.\d{2})', raw)
        return m.group(1) if m else raw

    def format_single_period(raw, is_apply=False):
        if not raw: return ""
        p = raw.split('~')
        if len(p) < 2: return raw
        s, e = simple_date(p[0]), simple_date(p[1])
        return f"~{e}" if is_apply else f"{s}~{e}"

    # ë°ì´í„° ì¶”ì¶œ
    apply_txt, oper_txt, cap_txt = "", "", ""
    
    if info['is_multi']:
        apply_txt = info['multi_calc']['apply']
        oper_txt = info['multi_calc']['oper']
        cap_txt = info['multi_calc']['capacity']
    else:
        apply_txt = format_single_period(info['apply_raw'], True)
        oper_txt = format_single_period(info['oper_raw'], False)
        cap_txt = info['capacity']

    # ì •ë³´ í•©ì¹˜ê¸°
    if apply_txt: parts.append(f"ì‹ ì²­: {apply_txt}")
    if oper_txt: parts.append(f"ìš´ì˜: {oper_txt}")
    if cap_txt: parts.append(f"ì •ì›: {cap_txt}")
    
    if parts:
        body_lines.append(" | ".join(parts))

    # 5. ë³¸ë¬¸ ë“¤ì—¬ì“°ê¸° ì²˜ë¦¬)
    body_text = ""
    for line in body_lines:
        body_text += f"> {line}\n"

    return header + body_text + "\n"

def send_batch_messages(new_items):
    if not new_items: return
    
    count = len(new_items)
    # [ë©”ì¸ í—¤ë”]
    full_message = f"### :compass: [CNU With+] ìƒˆë¡œìš´ ë¹„êµê³¼ {count}ê±´\n\n"
    
    for item in reversed(new_items):
        content_chunk = create_message_content(item)
        if len(full_message) + len(content_chunk) > 1900:
            post_to_discord_safe(full_message)
            full_message = ""
        full_message += content_chunk

    if full_message:
        post_to_discord_safe(full_message)

def send_simple_error_log(error_msg=None):
    if not MONITOR_WEBHOOK_URL: return 

    now = time.strftime('%Y-%m-%d %H:%M:%S')
    if error_msg:
        content = (
            f"ğŸš¨ **[WITH(ë¹„êµê³¼) ë´‡ ì˜¤ë¥˜]**\n"
            f"ì‹œê°„: {now}\n"
            f"ì—ëŸ¬: ```{error_msg}```\n"
            f"> ğŸ’¡ **ë¡œê·¸ì¸ ì‹¤íŒ¨**ë‚˜ **ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½**ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    else:
        content = f"ğŸš¨ **[WITH(ë¹„êµê³¼) ë´‡ ì˜¤ë¥˜]** \n{now}"
    
    try:
        requests.post(MONITOR_WEBHOOK_URL, json={"content": content}, timeout=5)
        print("âœ‰ [ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ]")
    except:
        print("âš  ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")

def run_selenium_scraper():
    print("\n" + "â”" * 40)
    print("ğŸ¤– WITH(ë¹„êµê³¼) ì•ŒëŒë´‡ ì‹¤í–‰")

    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.page_load_strategy = 'eager'

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        wait = WebDriverWait(driver, 20)

        print(f"â˜ ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì†...")
        driver.get("https://with.cnu.ac.kr/index.do")
        
        try:
            login_btn = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, "login_btn")))
            driver.execute_script("arguments[0].click();", login_btn)
        except: pass

        try:
            try:
                wait.until(EC.visibility_of_element_located((By.NAME, "userId"))).send_keys(USER_ID)
                driver.find_element(By.NAME, "password").send_keys(USER_PW + Keys.RETURN)
            except:
                found = False
                for frame in driver.find_elements(By.TAG_NAME, "iframe"):
                    driver.switch_to.default_content()
                    driver.switch_to.frame(frame)
                    try:
                        driver.find_element(By.NAME, "userId").send_keys(USER_ID)
                        driver.find_element(By.NAME, "password").send_keys(USER_PW + Keys.RETURN)
                        found = True
                        driver.switch_to.default_content()
                        break
                    except: continue
                if not found: 
                    send_simple_error_log("ë¡œê·¸ì¸ í¼ ê´€ë ¨ ì˜¤ë¥˜")
                    raise Exception("ë¡œê·¸ì¸ í¼ ëª» ì°¾ìŒ")
            
            try:
                wait.until(EC.invisibility_of_element_located((By.CLASS_NAME, "login_btn")))
                print("â˜‘ ë¡œê·¸ì¸ ì„±ê³µ")
            except:
                send_simple_error_log("ë¡œê·¸ì¸ ì‹¤íŒ¨")
                raise Exception("âš  ë¡œê·¸ì¸ ì‹¤íŒ¨ (ë¡œê·¸ì¸ ë²„íŠ¼ì´ ì‚¬ë¼ì§€ì§€ ì•ŠìŒ)")
        except Exception as e: raise e

        last_read_id = None
        is_first = False
        if os.path.exists(DATA_FILE):
            try:
                with open(DATA_FILE, "r", encoding="utf-8") as f:
                    last_read_id = json.load(f).get("last_read_id")
            except: pass
        if not last_read_id: is_first = True

        driver.get(LIST_URL)
        time.sleep(random.uniform(2, 4))
        try: wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "li div.cont_box")))
        except:
            send_simple_error_log("ëª©ë¡ ë¡œë”© ì‹¤íŒ¨")
            raise Exception("ëª©ë¡ ë¡œë”© ì‹¤íŒ¨")

        new_items = []
        stop = False
        top_id = None

        for page in range(1, 4): 
            if stop: break
            print(f"â˜ [í˜ì´ì§€ {page}] ìŠ¤ìº” ì¤‘...")
            if page > 1:
                try:
                    driver.execute_script(f"global.page({page});")
                    time.sleep(random.uniform(2, 4))
                except: break
            
            items = driver.find_elements(By.CSS_SELECTOR, "li:has(div.cont_box)")
            if not items: 
                items = [li for li in driver.find_elements(By.CSS_SELECTOR, "li") if li.find_elements(By.CLASS_NAME, "cont_box")]
            
            if not items:
                raise Exception(f"âš  [{page}í˜ì´ì§€] ê²Œì‹œê¸€ ëª©ë¡(li)ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (HTML êµ¬ì¡° ë³€ê²½ ì˜ì‹¬)")

            for item in items:
                try:
                    a_tag = item.find_element(By.CSS_SELECTOR, "a.tit")
                    pid = ""
                    try:
                        pid = pyjson.loads(a_tag.get_attribute("data-params")).get("encSddpbSeq")
                    except: pass
                    
                    if not pid: continue
                    if top_id is None: top_id = pid
                    if pid == last_read_id:
                        stop = True
                        break
                    if is_first: continue

                    link = f"https://with.cnu.ac.kr/ptfol/imng/icmpNsbjtPgm/findIcmpNsbjtPgmInfo.do?encSddpbSeq={pid}&paginationInfo.currentPageNo=1"
                    full_title = a_tag.get_attribute("textContent")
                    try: title = clean_text(full_title.replace(a_tag.find_element(By.CLASS_NAME, "label").get_attribute("textContent"), ""))
                    except: title = clean_text(full_title)
                    
                    try: d_day = clean_text(item.find_element(By.CSS_SELECTOR, "span.day").get_attribute("textContent"))
                    except: d_day = ""
                    
                    is_multi = "multi_class" in item.get_attribute("class")
                    p_data = {
                        "id": pid, "title": title, "d_day": d_day, "link": link,
                        "is_multi": is_multi, "sub_items": [], "multi_calc": {},
                        "apply_raw": "", "oper_raw": "", "capacity": ""
                    }

                    try:
                        more = item.find_elements(By.CLASS_NAME, "class_more_open")
                        if more and more[0].is_displayed():
                            driver.execute_script("arguments[0].click();", more[0])
                            time.sleep(0.5)
                    except: pass

                    if is_multi:
                        for sub in item.find_elements(By.CLASS_NAME, "class_cont"):
                            if not sub.get_attribute("textContent").strip(): continue
                            try:
                                s_title = sub.find_element(By.CSS_SELECTOR, "a.tit").get_attribute("textContent")
                                try: s_title = s_title.replace(sub.find_element(By.CLASS_NAME, "label").get_attribute("textContent"), "")
                                except: pass
                                p_data['sub_items'].append({"title": clean_text(s_title), **extract_details(sub)})
                            except: continue
                        p_data['multi_calc'] = calculate_multi_info(p_data['sub_items'])
                    else:
                        p_data.update(extract_details(item))
                    new_items.append(p_data)
                except: continue
        
        if is_first:
            if top_id:
                with open(DATA_FILE, "w", encoding="utf-8") as f: json.dump({"last_read_id": top_id}, f)
            print("â˜ ìµœì´ˆ ì‹¤í–‰ - ê¸°ì¤€ì  ì„¤ì • ì™„ë£Œ")
        elif new_items:
            print(f"â— {len(new_items)}ê°œ ìƒˆ ê¸€ -> ë¬¶ìŒ ì „ì†¡")
            send_batch_messages(new_items)
            if top_id:
                with open(DATA_FILE, "w", encoding="utf-8") as f: json.dump({"last_read_id": top_id}, f)
        else:
            print("â˜’ ìƒˆ ê¸€ ì—†ìŒ")

    except Exception as e:
        print(f"âš  ì—ëŸ¬: {e}")
        traceback.print_exc()
        # ìƒì„¸ ì—ëŸ¬ ì „ì†¡
        send_simple_error_log(f"í”„ë¡œê·¸ë¨ ê°•ì œ ì¢…ë£Œ\n{str(e)}")
    finally:
        if 'driver' in locals(): driver.quit()

if __name__ == "__main__":
    run_selenium_scraper()