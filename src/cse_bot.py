from curl_cffi import requests
from bs4 import BeautifulSoup
import os
import time
import json
import re
import urllib3
import traceback
import random
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from dotenv import load_dotenv

load_dotenv()

# ===[ì„¤ì • ì˜ì—­]==========================
DISCORD_WEBHOOK_URL = os.environ.get("cse_WEBHOOK_URL")
MONITOR_WEBHOOK_URL = os.environ.get("MONITOR_WEBHOOK_URL")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_FILE = os.path.join(BASE_DIR, "..", "data", "cse_data.json")

# ê²Œì‹œíŒ ëª©ë¡
TARGET_BOARDS = [
    {
        "id": "bachelor", 
        "name": "í•™ì‚¬ê³µì§€", 
        "url": "https://computer.cnu.ac.kr/computer/notice/bachelor.do?articleLimit=30"
    },
    {
        "id": "general", 
        "name": "êµë‚´ì¼ë°˜ì†Œì‹", 
        "url": "https://computer.cnu.ac.kr/computer/notice/notice.do?articleLimit=30" 
    },
    {
        "id": "job", 
        "name": "êµì™¸í™œë™Â·ì¸í„´Â·ì·¨ì—…", 
        "url": "https://computer.cnu.ac.kr/computer/notice/job.do?articleLimit=30" 
    },
    {
        "id": "project", 
        "name": "ì‚¬ì—…ë‹¨ì†Œì‹", 
        "url": "https://computer.cnu.ac.kr/computer/notice/project.do?articleLimit=30" 
    }
]

# í—¤ë” ì •ë³´
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    'Connection': 'keep-alive',
    'Referer': 'https://computer.cnu.ac.kr/',
    'Upgrade-Insecure-Requests': '1'
}
# ==========================================


# ===[ì„¸ì…˜ ìƒì„±ê¸°]===
def get_session():
    """Retry ê°€ëŠ¥í•œ ì„¸ì…˜ ìƒì„±"""
    session = requests.Session()
    return session


# ===[ID ì¶”ì¶œê¸°]===
def extract_article_id(link):
    """ë§í¬ì—ì„œ articleNo(ê³ ìœ ë²ˆí˜¸) ì¶”ì¶œ"""
    match = re.search(r'articleNo=(\d+)', link)
    if match:
        return int(match.group(1))
    return 0


# ===[ë””ì½” ì „ì†¡ê¸°]===
def send_discord_batch_alert(category_name, new_notices):
    """ë””ìŠ¤ì½”ë“œ ì „ì†¡"""
    if not new_notices:
        return

    if not DISCORD_WEBHOOK_URL:
        print("âš  ì›¹í›„í¬ URLì´ ì—†ìŒ")
        return
    
    count = len(new_notices)
    message_content = f"### ğŸ“¢ [{category_name}] ìƒˆ ê¸€ {count}ê±´\n\n"
    
    for notice in new_notices:
        icon = "â–¶" if notice['is_top'] else "â–·"
        message_content += f"{icon} [{notice['title']}](<{notice['link']}>)\n"

    try:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": message_content}, timeout=5)
        print(f"âœ‰ [ì „ì†¡ ì™„ë£Œ] {category_name} - {count}ê±´")
    except Exception as e:
        print(f"âš  [ì „ì†¡ ì‹¤íŒ¨] {e}")


# ===[ê´€ë¦¬ì ì•Œë¦¼]===
def send_simple_error_log(error_msg=None):
    """[ê´€ë¦¬ììš©] ì—ëŸ¬ ë°œìƒ ì‚¬ì‹¤ë§Œ ê°„ë‹¨í•˜ê²Œ ì•Œë¦¼"""
    if not MONITOR_WEBHOOK_URL:
        return 

    now = time.strftime('%Y-%m-%d %H:%M:%S')
    if error_msg:
        content = (
            f"ğŸš¨ **[CSE ê³µì§€ë´‡ ì ‘ì† ì¥ì• ]**\n"
            f"ì‹œê°„: {now}\n"
            f"ì—ëŸ¬: ```{error_msg}```\n"
            f"> ğŸ’¡ **IP ì°¨ë‹¨**ì´ë‚˜ **ì„œë²„ ì ê²€**ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    else:
        content = f"ğŸš¨ **[CSE ê³µì§€ë´‡ ì¹˜ëª…ì  ì˜¤ë¥˜]** \n{now}"
    
    try:
        requests.post(MONITOR_WEBHOOK_URL, json={"content": content}, timeout=5)
        print("âœ‰ [ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ]")
    except:
        print("âš  ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")


# ===[ê²Œì‹œíŒ ê²€ì‚¬]===
def check_board(session, board_info, saved_data):
    """ê°œë³„ ê²Œì‹œíŒ í™•ì¸ ë° ìƒˆ ê¸€ ê°ì§€"""
    board_id = board_info["id"]
    board_name = board_info["name"]
    url = board_info["url"]

    print(f"â— [{board_name}] ë¶„ì„ ì¤‘...")

    try:
        sleep_time = random.uniform(3, 6) 
        time.sleep(sleep_time)
        
        # ì°¨ë‹¨ ë°©ì§€? (ì›ë¦¬ëŠ” ì˜ ëª¨ë¥´ê² ìŒ...)
        response = session.get(url, headers=HEADERS, timeout=30, impersonate="chrome120")
        
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        rows = soup.select('table.board-table tbody tr')
        
        if not rows:
            print(f"âš  [{board_name}] ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (HTML êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±)")
            return False
        
        last_id = saved_data.get(board_id, 0)
        new_notices = []
        max_id = last_id

        for row in rows:
            title_div = row.select_one('.b-title-box > a')
            if not title_div:
                continue 

            title = title_div.get('title') or title_div.text.strip()
            title = title.replace("ìì„¸íˆ ë³´ê¸°", "").strip()
            
            href = title_div.get('href')
            
            if href.startswith('?'):
                base_url = url.split('?')[0]
                link = f"{base_url}{href}"
            else:
                link = href
            
            article_id = extract_article_id(link)
            if article_id == 0:
                continue

            row_classes = row.get('class', [])
            is_top = 'b-top-box' in row_classes

            if article_id > last_id:
                new_notices.append({
                    "id": article_id,
                    "title": title,
                    "link": link,
                    "is_top": is_top
                })
                if article_id > max_id:
                    max_id = article_id

        # ìµœì´ˆ ì‹¤í–‰ ì²˜ë¦¬
        if last_id == 0 and max_id > 0:
            print(f"â˜ [{board_name}] ìµœì´ˆ ì‹¤í–‰ - ê¸°ì¤€ì (ID: {max_id})ë§Œ ì„¤ì •, ì „ì†¡ X")
            saved_data[board_id] = max_id
            return True
        
        # ìƒˆ ê¸€ì´ ìˆìœ¼ë©´ ì²˜ë¦¬
        if new_notices:
            new_notices.sort(key=lambda x: x['id'])
            send_discord_batch_alert(board_name, new_notices)
            saved_data[board_id] = max_id
            return True
        
        return False

    except Exception as e:
        print(f"âš  [{board_name}] ì—ëŸ¬: {e}")
        send_simple_error_log(f"[{board_name}] ì ‘ì† ì‹¤íŒ¨\n{str(e)}")
        return False


# ===[MAIN]===
def run_bot():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "â”" * 40)
    print(f"ğŸ¤– CSE ê³µì§€ë´‡ ì‹¤í–‰: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # SSL ê²½ê³  ë¬´ì‹œ
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    try:
        saved_data = {}

        # íŒŒì¼ ì½ê¸°
        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, "r", encoding="utf-8") as f:
                try:
                    saved_data = json.load(f)
                except:
                    saved_data = {}

        session = get_session()
        any_changes = False

        # ê²Œì‹œíŒ ëª©ë¡ ë°˜ë³µ
        for board in TARGET_BOARDS:
            if check_board(session, board, saved_data):
                any_changes = True
        
        # ë³€ê²½ì‚¬í•­ ìˆìœ¼ë©´ ì €ì¥
        if any_changes:
            with open(DATA_FILE, "w", encoding="utf-8") as f:
                json.dump(saved_data, f, ensure_ascii=False, indent=4)
            print("â˜‘ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        else:
            print("â˜’ ë³€ë™ ì‚¬í•­ ì—†ìŒ")

    except Exception as e:
        print(f"âš  ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        send_simple_error_log(f"í”„ë¡œê·¸ë¨ ê°•ì œ ì¢…ë£Œ\n{str(e)}")


if __name__ == "__main__":
    run_bot()