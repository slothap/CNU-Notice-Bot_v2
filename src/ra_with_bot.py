import os
import time
import json
import requests
import re
import traceback
from datetime import datetime
from dotenv import load_dotenv
import random
import json as pyjson

# ===[ì…€ë ˆë‹ˆì›€ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬]===
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

load_dotenv()

# ===[ì„¤ì • ì˜ì—­]==========================
# 1ì‹œê°„ ì£¼ê¸° (ì´ˆ)
CHECK_INTERVAL = 3600

# [ì¬ì‹œë„ ì„¤ì •]
MAX_RETRIES = 3
RETRY_DELAY = 60

USER_ID = os.environ.get("CNU_ID")
USER_PW = os.environ.get("CNU_PW")
DISCORD_WEBHOOK_URL = os.environ.get("with_WEBHOOK_URL")
MONITOR_WEBHOOK_URL = os.environ.get("MONITOR_WEBHOOK_URL")

LIST_URL = "https://with.cnu.ac.kr/ptfol/imng/icmpNsbjtPgm/findIcmpNsbjtPgmList.do"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
DATA_FILE = os.path.join(DATA_DIR, "with_data.json")

PROFILE_DIR = os.path.join(BASE_DIR, "chrome_profile")
if not os.path.exists(PROFILE_DIR):
    os.makedirs(PROFILE_DIR)
# ==========================================

# === [í•¨ìˆ˜] ===
def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', text).strip()

def parse_str_to_dt(date_str):
    if not date_str: return None
    try:
        if ":" in date_str:
            return datetime.strptime(date_str, "%Y.%m.%d %H:%M")
        else:
            return datetime.strptime(date_str, "%Y.%m.%d")
    except:
        return None

# [new] ë©€í‹° í”„ë¡œê·¸ë¨ ì •ë³´ ê³„ì‚° (ì¸ì •ì‹œê°„ ìµœëŒ€ê°’ ë¡œì§)
def calculate_multi_info(sub_items):
    if not sub_items: return None
    app_ends, oper_starts, oper_ends, capacities = [], [], [], []
    time_values = [] # ì¸ì •ì‹œê°„ ìˆ«ìë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸

    for item in sub_items:
        # 1. ì‹ ì²­ ê¸°ê°„
        if item['apply_raw']:
            parts = item['apply_raw'].split('~')
            if len(parts) > 1:
                dt = parse_str_to_dt(parts[1].strip())
                if dt: app_ends.append(dt)
        # 2. ìš´ì˜ ê¸°ê°„
        if item['oper_raw']:
            parts = item['oper_raw'].split('~')
            if len(parts) > 0:
                dt_s = parse_str_to_dt(parts[0].strip())
                if dt_s: oper_starts.append(dt_s)
            if len(parts) > 1:
                dt_e = parse_str_to_dt(parts[1].strip())
                if dt_e: oper_ends.append(dt_e)
            elif len(parts) == 1 and dt_s:
                oper_ends.append(dt_s)
        
        # 3. ì •ì›
        if item['capacity']:
            nums = re.findall(r'\d+', item['capacity'])
            if nums: capacities.append(int(nums[0]))
        
        # 4. [NEW] ì¸ì •ì‹œê°„ ìˆ«ì ì¶”ì¶œ
        if item['time_raw']:
            # "3.0 ì‹œê°„", "2ì‹œê°„" ë“±ì—ì„œ ìˆ«ì(ì†Œìˆ˜ì  í¬í•¨) ì¶”ì¶œ
            t_nums = re.findall(r"[\d\.]+", item['time_raw'])
            if t_nums:
                try: time_values.append(float(t_nums[0]))
                except: pass

    result = {"apply": "", "oper": "", "capacity": "", "max_time": ""}
    
    if app_ends:
        result['apply'] = f"~{min(app_ends).strftime('%m.%d')}"
    if oper_starts and oper_ends:
        min_s, max_e = min(oper_starts), max(oper_ends)
        if min_s.date() == max_e.date():
            result['oper'] = f"{min_s.strftime('%m.%d %H:%M')}~{max_e.strftime('%H:%M')}"
        else:
            result['oper'] = f"{min_s.strftime('%m.%d')}~{max_e.strftime('%m.%d')}"
    if capacities:
        result['capacity'] = f"{min(capacities)}ëª…"
    
    # [NEW] ì¸ì •ì‹œê°„ ì¤‘ ê°€ì¥ í° ê°’ ì„ íƒ
    if time_values:
        max_t = max(time_values)
        # ì†Œìˆ˜ì ì´ .0ì´ë©´ ì •ìˆ˜ë¡œ ë³€í™˜gka (3.0 -> 3)
        if max_t.is_integer():
            result['max_time'] = f"{int(max_t)}ì‹œê°„"
        else:
            result['max_time'] = f"{max_t}ì‹œê°„"
            
    return result

# [new] ìƒì„¸ ì •ë³´ ì¶”ì¶œ - ì¸ì •ì‹œê°„ ì¶”ê°€ë¨
def extract_details(container):
    data = {"apply_raw": "", "oper_raw": "", "capacity": "", "time_raw": ""}
    
    # 1. ìƒë‹¨ ì •ë³´ (.etc_info_txt) - ì‹ ì²­/ìš´ì˜ ê¸°ê°„
    try:
        # .etc_info_txt ë‚´ë¶€ì˜ dl
        for dl in container.find_elements(By.CSS_SELECTOR, ".etc_info_txt dl"):
            dt = dl.find_element(By.TAG_NAME, "dt").get_attribute("textContent")
            dd = dl.find_element(By.TAG_NAME, "dd").get_attribute("textContent")
            
            if "ì‹ ì²­" in dt: 
                data["apply_raw"] = clean_text(dd)
            elif "ìš´ì˜" in dt or "êµìœ¡ê¸°ê°„" in dt: 
                data["oper_raw"] = clean_text(dd)
    except: pass

    # 2. í•˜ë‹¨ ì •ë³´ ().rq_desc) - ì •ì› ë° ì¸ì •ì‹œê°„
    try:
        #.rq_desc ë‚´ë¶€ì˜ dl
        rq_desc = container.find_element(By.CSS_SELECTOR, ".rq_desc")
        
        # (1) ì •ì› ì°¾ê¸°
        for dl in rq_desc.find_elements(By.TAG_NAME, "dl"):
            dt_text = dl.find_element(By.TAG_NAME, "dt").get_attribute("textContent")
            if "ëª¨ì§‘" in dt_text or "ì •ì›" in dt_text:
                data["capacity"] = clean_text(dl.find_element(By.TAG_NAME, "dd").get_attribute("textContent"))

        # (2) [NEW] ì¸ì •ì‹œê°„ ì°¾ê¸° (dl class="mileage") ì´ë ‡ê²Œ ìƒê¹€!
        try:
            mileage_dl = rq_desc.find_element(By.CLASS_NAME, "mileage")
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜ˆ: "3.0 ì‹œê°„")
            data["time_raw"] = clean_text(mileage_dl.find_element(By.TAG_NAME, "dd").get_attribute("textContent"))
        except: 
            pass # mileage í´ë˜ìŠ¤ê°€ ì—†ì„ ê²½ìš° íŒ¨ìŠ¤ (ì˜¤ë¥˜ ë°©ì§€!)

    except: pass
    
    return data

# === [ë””ìŠ¤ì½”ë“œ ì•Œë¦¼ í•¨ìˆ˜] ===
def post_to_discord_safe(content):
    if not DISCORD_WEBHOOK_URL: return
    try:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": content}, timeout=10)
        print("âœ‰ [ì•Œë¦¼ ì „ì†¡ ì„±ê³µ]")
    except Exception as e:
        print(f"âš  [ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨] {e}")

def send_simple_error_log(error_msg=None, is_fatal=False):
    if not MONITOR_WEBHOOK_URL: return
    now = time.strftime('%Y-%m-%d %H:%M:%S')
    title = "ğŸš¨ **[WITH ë´‡ ì¹˜ëª…ì  ì˜¤ë¥˜]**" if is_fatal else "âš  **[WITH ë´‡ ê²½ê³ ]**"
    content = f"{title}\nì‹œê°„: {now}\n"
    if error_msg: content += f"ë‚´ìš©: ```{error_msg}```"
    if is_fatal: content += "\n> ğŸ“¢ **ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨. ë´‡ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.**"
    try: requests.post(MONITOR_WEBHOOK_URL, json={"content": content}, timeout=5)
    except: pass

# [í•µì‹¬] ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜ (ì¸ì •ì‹œê°„ í‘œì‹œ ì¶”ê°€)
def create_message_content(info):
    icon = "â–¶" if info['is_multi'] else "â–·"
    d_day_part = f"{info['d_day']} | " if info['d_day'] else ""
    header = f"** {icon} {d_day_part}[{info['title']}](<{info['link']}>) **\n"
    body_lines = []

    if info['is_multi'] and info['sub_items']:
        first_sub = info['sub_items'][0]['title']
        count = len(info['sub_items']) - 1
        sub_text = f"[{first_sub}] ì™¸ {count}ê°œ ë°˜" if count > 0 else f"[{first_sub}]"
        body_lines.append(sub_text)

    parts = []
    def simple_date(raw):
        m = re.search(r'\d{4}\.(\d{2}\.\d{2})', raw)
        return m.group(1) if m else raw

    def format_single_period(raw, is_apply=False):
        if not raw: return ""
        p = raw.split('~')
        if len(p) < 2: return raw
        s, e = simple_date(p[0]), simple_date(p[1])
        return f"~{e}" if is_apply else f"{s}~{e}"

    apply_txt, oper_txt, cap_txt, time_txt = "", "", "", ""
    
    if info['is_multi']:
        apply_txt = info['multi_calc']['apply']
        oper_txt = info['multi_calc']['oper']
        cap_txt = info['multi_calc']['capacity']
        time_txt = info['multi_calc']['max_time'] # ê³„ì‚°ëœ ìµœëŒ€ ì‹œê°„
    else:
        apply_txt = format_single_period(info['apply_raw'], True)
        oper_txt = format_single_period(info['oper_raw'], False)
        cap_txt = info['capacity']
        # "3.0 ì‹œê°„" ë“±ì—ì„œ ìˆ«ìë§Œ ê¹”ë”í•˜ê²Œ ë‚¨ê¸°ê³  ì‹¶ë‹¤ë©´ ì—¬ê¸°ì„œë„ ì •ë¦¬ ê°€ëŠ¥í•˜ì§€ë§Œ, rawë„ ê´œì°®ìŒ
        time_txt = info['time_raw'] 

    if apply_txt: parts.append(f"ì‹ ì²­: {apply_txt}")
    if oper_txt: parts.append(f"ìš´ì˜: {oper_txt}")
    if cap_txt: parts.append(f"ì •ì›: {cap_txt}")
    if time_txt: parts.append(f"ì¸ì •: {time_txt}") # [NEW] ì•Œë¦¼ ë©”ì‹œì§€ì— ì¶”ê°€

    if parts: body_lines.append(" | ".join(parts))

    body_text = ""
    for line in body_lines:
        body_text += f"> {line}\n"
    return header + body_text + "\n"

def send_batch_messages(new_items):
    if not new_items: return
    count = len(new_items)
    full_message = f"### :compass: [CNU With+] ìƒˆë¡œìš´ ë¹„êµê³¼ {count}ê±´\n\n"
    for item in reversed(new_items):
        content_chunk = create_message_content(item)
        if len(full_message) + len(content_chunk) > 1900:
            post_to_discord_safe(full_message)
            full_message = ""
        full_message += content_chunk
    if full_message: post_to_discord_safe(full_message)

# === [ë¸Œë¼ìš°ì € ìƒì„± í•¨ìˆ˜] ===
def create_driver():
    chrome_options = Options()
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ë¸Œë¼ìš°ì € ì°½ì„ ë³´ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ headless ì¤„ì„ ì£¼ì„ ì²˜ë¦¬(#) í•˜ì„¸ìš”
    # chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    
    # [í•µì‹¬] í”„ë¡œí•„ ìœ ì§€
    chrome_options.add_argument(f"user-data-dir={PROFILE_DIR}")

    # === [ìˆ˜ì •ëœ ë¶€ë¶„: ë“œë¼ì´ë²„ ê²½ë¡œ ìë™ ì„ íƒ] ===
    server_driver_path = "/usr/bin/chromedriver"
    
    if os.path.exists(server_driver_path):
        # 1. ì„œë²„ í™˜ê²½ (íŒŒì¼ì´ ì¡´ì¬í•¨)
        print(f"ğŸ’» ì„œë²„ í™˜ê²½ ê°ì§€: {server_driver_path} ì‚¬ìš©")
        service = Service(server_driver_path)
    else:
        # 2. ë¡œì»¬ í™˜ê²½ (íŒŒì¼ì´ ì—†ìŒ -> ìë™ ê´€ë¦¬)
        # Selenium 4.6+ ë²„ì „ë¶€í„°ëŠ” ë“œë¼ì´ë²„ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì•Œì•„ì„œ ì„¤ì¹˜/ì‹¤í–‰í•©ë‹ˆë‹¤.
        print("ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€: ë“œë¼ì´ë²„ ìë™ ê´€ë¦¬ ëª¨ë“œ ì‚¬ìš©")
        service = Service() 

    return webdriver.Chrome(service=service, options=chrome_options)
def login_process(driver, wait):
    driver.get("https://with.cnu.ac.kr/index.do")
    try:
        if len(driver.find_elements(By.CLASS_NAME, "login_btn")) == 0:
            print("â˜‘ ìë™ ë¡œê·¸ì¸ ì„±ê³µ (ì„¸ì…˜ ìœ ì§€)")
            return
    except: pass
    print("â˜ ë¡œê·¸ì¸ ì‹œë„ ì¤‘...")
    try:
        login_btn = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, "login_btn")))
        driver.execute_script("arguments[0].click();", login_btn)
    except: pass
    try:
        try:
            wait.until(EC.visibility_of_element_located((By.NAME, "userId"))).send_keys(USER_ID)
            driver.find_element(By.NAME, "password").send_keys(USER_PW + Keys.RETURN)
        except:
            found = False
            for frame in driver.find_elements(By.TAG_NAME, "iframe"):
                driver.switch_to.default_content()
                driver.switch_to.frame(frame)
                try:
                    driver.find_element(By.NAME, "userId").send_keys(USER_ID)
                    driver.find_element(By.NAME, "password").send_keys(USER_PW + Keys.RETURN)
                    found = True
                    driver.switch_to.default_content()
                    break
                except: continue
            if not found: raise Exception("ë¡œê·¸ì¸ í¼ ì°¾ê¸° ì‹¤íŒ¨")
        try:
            wait.until(EC.invisibility_of_element_located((By.CLASS_NAME, "login_btn")))
            print("â˜‘ ì‹ ê·œ ë¡œê·¸ì¸ ì„±ê³µ")
        except:
            raise Exception("ë¡œê·¸ì¸ ë²„íŠ¼ ë¯¸ì†Œë©¸")
    except Exception as e:
        raise e

# === [ë©”ì¸ ë¡œì§] ===
def perform_scraping_cycle():
    driver = None
    try:
        driver = create_driver()
        wait = WebDriverWait(driver, 20)
        login_process(driver, wait)

        last_read_id = None
        is_first = False
        if os.path.exists(DATA_FILE):
            try:
                with open(DATA_FILE, "r", encoding="utf-8") as f:
                    last_read_id = json.load(f).get("last_read_id")
            except: pass
        if not last_read_id: is_first = True

        driver.get(LIST_URL)
        time.sleep(random.uniform(2, 4))

        new_items = []
        stop = False
        top_id = None

        for page in range(1, 4):
            if stop: break
            if page > 1:
                try:
                    driver.execute_script(f"global.page({page});")
                    time.sleep(random.uniform(2, 4))
                except: break

            items = driver.find_elements(By.CSS_SELECTOR, "li:has(div.cont_box)")
            if not items:
                items = [li for li in driver.find_elements(By.CSS_SELECTOR, "li") if li.find_elements(By.CLASS_NAME, "cont_box")]
            if not items: continue

            for item in items:
                try:
                    a_tag = item.find_element(By.CSS_SELECTOR, "a.tit")
                    pid = ""
                    try: pid = pyjson.loads(a_tag.get_attribute("data-params")).get("encSddpbSeq")
                    except: pass
                    if not pid: continue
                    if top_id is None: top_id = pid
                    if pid == last_read_id:
                        stop = True
                        break
                    if is_first: continue

                    link = f"https://with.cnu.ac.kr/ptfol/imng/icmpNsbjtPgm/findIcmpNsbjtPgmInfo.do?encSddpbSeq={pid}&paginationInfo.currentPageNo=1"
                    full_title = a_tag.get_attribute("textContent")
                    try: title = clean_text(full_title.replace(a_tag.find_element(By.CLASS_NAME, "label").get_attribute("textContent"), ""))
                    except: title = clean_text(full_title)
                    try: d_day = clean_text(item.find_element(By.CSS_SELECTOR, "span.day").get_attribute("textContent"))
                    except: d_day = ""

                    is_multi = "multi_class" in item.get_attribute("class")
                    p_data = {
                        "id": pid, "title": title, "d_day": d_day, "link": link,
                        "is_multi": is_multi, "sub_items": [], "multi_calc": {},
                        "apply_raw": "", "oper_raw": "", "capacity": "", "time_raw": ""
                    }

                    try:
                        more = item.find_elements(By.CLASS_NAME, "class_more_open")
                        if more and more[0].is_displayed():
                            driver.execute_script("arguments[0].click();", more[0])
                            time.sleep(0.5)
                    except: pass

                    if is_multi:
                        for sub in item.find_elements(By.CLASS_NAME, "class_cont"):
                            if not sub.get_attribute("textContent").strip(): continue
                            try:
                                s_title = sub.find_element(By.CSS_SELECTOR, "a.tit").get_attribute("textContent")
                                try: s_title = s_title.replace(sub.find_element(By.CLASS_NAME, "label").get_attribute("textContent"), "")
                                except: pass
                                p_data['sub_items'].append({"title": clean_text(s_title), **extract_details(sub)})
                            except: continue
                        p_data['multi_calc'] = calculate_multi_info(p_data['sub_items'])
                    else:
                        p_data.update(extract_details(item))

                    new_items.append(p_data)
                except: continue

        if is_first:
            if top_id:
                with open(DATA_FILE, "w", encoding="utf-8") as f: json.dump({"last_read_id": top_id}, f)
            print("â˜ ìµœì´ˆ ì‹¤í–‰ - ê¸°ì¤€ì  ì„¤ì • ì™„ë£Œ")
        elif new_items:
            print(f"â— {len(new_items)}ê°œ ìƒˆ ê¸€ ë°œê²¬")
            send_batch_messages(new_items)
            if top_id:
                with open(DATA_FILE, "w", encoding="utf-8") as f: json.dump({"last_read_id": top_id}, f)
        else:
            print("â˜’ ìƒˆ ê¸€ ì—†ìŒ")

    except Exception as e:
        raise e
    finally:
        if driver:
            try: driver.quit()
            except: pass

def run_selenium_scraper():
    print(f"ğŸš€ WITH(ë¹„êµê³¼) ë´‡ ì‹œì‘ (ì£¼ê¸°: {CHECK_INTERVAL}ì´ˆ, ì¬ì‹œë„: {MAX_RETRIES}íšŒ)")
    try:
        while True:
            print("\n" + "â”" * 40)
            print(f"â° ê²€ì‚¬ ì‹œì‘: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            success = False
            last_error = ""
            for attempt in range(1, MAX_RETRIES + 1):
                try:
                    perform_scraping_cycle()
                    success = True
                    break
                except Exception as e:
                    last_error = str(e)
                    print(f"âš  [ì‹œë„ {attempt}/{MAX_RETRIES}] ì—ëŸ¬: {e}")
                    if attempt < MAX_RETRIES:
                        print(f"â³ {RETRY_DELAY}ì´ˆ í›„ ì¬ì‹œë„...")
                        time.sleep(RETRY_DELAY)
            if not success:
                error_msg = f"{MAX_RETRIES}íšŒ ì¬ì‹œë„ ì‹¤íŒ¨.\në§ˆì§€ë§‰ ì—ëŸ¬: {last_error}\n{traceback.format_exc()}"
                print("âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨. ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡.")
                send_simple_error_log(error_msg, is_fatal=True)
            print(f"ğŸ’¤ {CHECK_INTERVAL}ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(CHECK_INTERVAL)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    run_selenium_scraper()